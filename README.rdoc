= SKINNY JEANS LOG PARSING WITH RUBY & SQLITE FOR HIPSTERS
http://img696.imageshack.us/img696/75/skinnys3.jpg

== WHY?
*  so you can query a database by date and path and get pageviews and have that data stored CHEAP
*  because i couldn't find anything simpler and Google Analytics is limited to 10,000 API requests per day


== Requirements
1.  some NGINX or Apache log to parse
2.  Ruby >= 1.8.6 maybe
3.  GEMS: sqlite3-ruby >= 1.2.4, active_record >= 3.0.0, home_run >= 0.9.3
4.  this is some jank


== Usage
  SkinnyJeans::execute(logfile_path = "access.log", sqlite_skinny_jeans = "sqlite_skinny_jeans.db", path_regexp = /\s\/posts\/(.*)\sHTTP/, date_regexp = /\[(\d.*\d)\]/)
1.  Parse oldest logs first, then run regularly against your main log, let logrotate handle the rest (skinny_jeans remembers where it left off)
2.  enjoy the skinny jeans


== WHAT IT DO
*  it parses 100,000 lines in < 2.5 seconds
*  persists 1,000 requests with 2 compound indexes in 10 seconds (using home_run c date parser, 15 seconds without home_run)

*  parse a webserver's log file to aggregate paths by DAY with pageview counts

*  creates sqlite database with columns: date, path, pageview_count

*  ASSUMES reading log files in ascending order, keeps track of last line read so you could put it on a scheduler or cron job